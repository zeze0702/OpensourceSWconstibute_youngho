#ORB
import numpy as np
import cv2
from matplotlib import pyplot as plt
import glob
import os

img_list = glob.glob('/home/john/PycharmProjects/MOT_test/person_frame/train/*.jpg')
# dir_img_list = glob.glob('/home/john/PycharmProjects/MOT_test/person_frame/*.jpg')


for i in range(len(img_list[:20])):
    img1 = cv2.imread(f'{img_list[7]}',0)          # queryImage
    img2 = cv2.imread(f'{img_list[i]}',0) # trainImage

    orb = cv2.ORB_create()
    kp1, des1 = orb.detectAndCompute(img1,None)
    kp2, des2 = orb.detectAndCompute(img2,None)
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    try:
        matches = bf.match(des1,des2)
        matches = sorted(matches, key = lambda x:x.distance)
        img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=2)
        plt.imshow(img3),plt.show()

    except:
        print('유사도 없음')
        
#SIFT     
import numpy as np
import cv2
from matplotlib import pyplot as plt
import glob
import os


img_list = glob.glob('/home/john/PycharmProjects/MOT_test/person_frame/train/*.jpg')
# dir_img_list = glob.glob('/home/john/PycharmProjects/MOT_test/person_frame/*.jpg')

for i in range(len(img_list)):
    img1 = cv2.imread(f'{img_list[0]}',0)          # queryImage
    img2 = cv2.imread(f'{img_list[i]}',0) # trainImage

    sift = cv2.xfeatures2d.SIFT_create()
    kp1, des1 = sift.detectAndCompute(img1,None)
    kp2, des2 = sift.detectAndCompute(img2,None)
    bf = cv2.BFMatcher()

    matches = bf.knnMatch(des1,des2, k=2)
    good = []

    for m,n in matches:
        # if m.distance < 0.3*n.distance:
        if m.distance < n.distance:

            good.append([m])
    print('same_good', good)
    img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)
    plt.imshow(img3),plt.show()
    cv2.imshow("comapre", img3)
    cv2.waitKey(1) 
    

#auto incoder
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.init as init
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import logging
import sys

flag = 0 # if 1 train  0 test

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
logger.addHandler(logging.StreamHandler(sys.stdout))

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
mnist_train = dset.MNIST("./", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)
mnist_test = dset.MNIST("./", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)

class Encoder(nn.Module):
  def __init__(self, latency_num):
      super(Encoder, self).__init__()
      self.layer1 = nn.Sequential(
          nn.Conv2d(1, 16, 3, padding=1),  # batch x 16 x 28 x 28
          nn.ReLU(),
          nn.BatchNorm2d(16),
          nn.Conv2d(16, 32, 3, padding=1),  # batch x 32 x 28 x 28
          nn.ReLU(),
          nn.BatchNorm2d(32),
          nn.Conv2d(32, 64, 3, padding=1),  # batch x 64 x 28 x 28
          nn.ReLU(),
          nn.BatchNorm2d(64),
          nn.MaxPool2d(2, 2)  # batch x 64 x 14 x 14
      )
      self.layer2 = nn.Sequential(
          nn.Conv2d(64, 128, 3, padding=1),  # batch x 128 x 14 x 14
          nn.ReLU(),
          nn.BatchNorm2d(128),
          nn.MaxPool2d(2, 2),
          nn.Conv2d(128, 256, 3, padding=1),  # batch x 256 x 7 x 7
          nn.ReLU()
      )
      self.fc1 = nn.Linear(256 * 7 * 7, latency_num)

      self.hidden2mu = nn.Linear(1024,1024)
      self.hidden2log_var = nn.Linear(1024,1024)
      self.relu = nn.ReLU()

  def forward(self, x):
      out = self.layer1(x)
      out = self.layer2(out)
      out = out.view(batch_size, -1)
      out = self.fc1(out)
      # mu = self.hidden2mu(out)
      # mu = self.relu(mu)
      # log_var = self.hidden2log_var(out)
      # log_var = self.relu(log_var)
      #
      # std = torch.exp(0.5*log_var)
      # eps = torch.randn_like(std)
      #out = mu + eps*std
      return out



class Decoder(nn.Module):
  def __init__(self,latency_num):
      super(Decoder, self).__init__()
      self.layer1 = nn.Sequential(
          nn.ConvTranspose2d(256, 128, 3, 2, 1, 1),  # batch x 128 x 14 x 14
          nn.ReLU(),
          nn.BatchNorm2d(128),
          nn.ConvTranspose2d(128, 64, 3, 1, 1),  # batch x 64 x 14 x 14
          nn.ReLU(),
          nn.BatchNorm2d(64)
      )
      self.layer2 = nn.Sequential(
          nn.ConvTranspose2d(64, 16, 3, 1, 1),  # batch x 16 x 14 x 14
          nn.ReLU(),
          nn.BatchNorm2d(16),
          nn.ConvTranspose2d(16, 1, 3, 2, 1, 1),  # batch x 1 x 28 x 28
          nn.ReLU()
      )
      self.fc1 = nn.Linear(latency_num, 256 * 7 * 7)

  def forward(self, x):
      out = self.fc1(x)
      out = out.view(batch_size, 256, 7, 7)
      out = self.layer1(out)
      out = self.layer2(out)
      return out

def cosin_metric(x1, x2):
  return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))

def loss_function(recon_x, x, mu, logvar):
  BCE = nn.functional.binary_cross_entropy(recon_x, x)

  # see Appendix B from VAE paper:
  # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014
  # https://arxiv.org/abs/1312.6114
  # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
  KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
  #kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)

  return BCE + KLD

def discrete_cmap(N, base_cmap=None):
  """Create an N-bin discrete colormap from the specified input map"""

  # Note that if base_cmap is a string or None, you can simply do
  #    return plt.cm.get_cmap(base_cmap, N)
  # The following works for string, None, or a colormap instance:

  base = plt.cm.get_cmap(base_cmap)
  color_list = base(np.linspace(0, 1, N))
  cmap_name = base.name + str(N)
  return base.from_list(cmap_name, color_list, N)

if __name__ == "__main__":
  avg_list = []
  min_list=[]
  max_list = []
  var_list=[]

  for latency_num in range(2,20):

      learning_rate = 0.0002
      num_epoch = 5
      batch_size = 256
      train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2,
                                                 drop_last=True)

      #     loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)
      test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2,
                                                drop_last=True)
      encoder = Encoder(latency_num=latency_num).to(device)
      decoder = Decoder(latency_num=latency_num).to(device)

      #train
      if flag==1:
          # 인코더 디코더의 파라미터를 동시에 학습시키기 위해
          parameters = list(encoder.parameters()) + list(decoder.parameters())
          loss_func = nn.MSELoss()

          optimizer = torch.optim.Adam(parameters, lr=learning_rate)

          for epoch in range(num_epoch):
              train_loss = 0
              for batch_idx, [image, label] in enumerate(train_loader):
                  optimizer.zero_grad()
                  image = image.to(device)

                  output= encoder(image)
                  output = decoder(output)
                  loss = loss_func(output, image)
                  loss.backward()
                  train_loss += loss.item()
                  optimizer.step()

                  if batch_idx % 10 == 0:
                      logger.info('Train Epoch: {}/{} [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(
                          epoch,num_epoch, batch_idx * len(image), len(train_loader.sampler),
                                 100. * batch_idx / len(train_loader), loss.item()))
              print('====> Epoch: {} Average loss: {:.4f}'.format(
                  epoch, train_loss / len(train_loader.dataset)))

                  # out_img = torch.squeeze(output.cpu().data)
                  # print(out_img.size())
                  # plt.subplot(1, 2, 1)
                  # plt.imshow(torch.squeeze(image[0]).cpu().numpy(), cmap='gray')
                  # plt.subplot(1, 2, 2)
                  # plt.imshow(out_img[0].numpy(), cmap='gray')
                  # plt.show()

          torch.save(encoder.cpu().state_dict(), f'./encoder_model/{latency_num}_encoder.pt')
          torch.save(decoder.cpu().state_dict(), f'./encoder_model/{latency_num}_decoder.pt')
          # train 결과 체크

      # test
      if  flag==0 :
          tt = []
          all = []
          encoder.load_state_dict(torch.load(f'./encoder_model/{latency_num}_encoder.pt'))
          decoder.load_state_dict(torch.load(f'./encoder_model/{latency_num}_decoder.pt'))
          encoder.eval()
          decoder.eval()
          with torch.no_grad():
              for j, [image, label] in enumerate(test_loader):
                  image = image.to(device)

                  outputs = encoder(image)
                  output = decoder(outputs)

                  out_img = torch.squeeze(output.cpu().data)

                  # plt.subplot(1, 2, 1)
                  # plt.imshow(torch.squeeze(image[0]).cpu().numpy(), cmap='gray')
                  # plt.subplot(1, 2, 2)
                  # plt.imshow(out_img[0].numpy(), cmap='gray')
                  # plt.show()
                  N = 10
                  plt.figure(figsize=(6, 6))
                  plt.scatter(outputs[:, 0].cpu().numpy(), outputs[:, 1].cpu().numpy(), c=label, marker='o',
                              edgecolor='none', cmap=discrete_cmap(N, 'jet'))
                  plt.colorbar(ticks=range(N))
                  plt.show()

                  for idx, la in enumerate(label) :
                      if la == 1:
                          latent_ = outputs[idx].view(-1).cpu().numpy()
                          tt.append(latent_)
                      else :
                          latent_s = outputs[idx].view(-1).cpu().numpy()
                          all.append(latent_s)



          tot = []
          for tt_idx in range(len(tt)-1):
              temp = cosin_metric(tt[0],tt[tt_idx+1])
              tot.append(temp)
              print(temp)
          print("avg = ",sum(tot, 0.0)/len(tot))
          print("min = ",min(tot))
          print("max = ",max(tot))
          print("total = ",len(tot))
          avg_list.append(sum(tot, 0.0)/len(tot))
          min_list.append(min(tot))
          max_list.append(max(tot))
          var_list.append(np.var(tot))

  print(avg_list.index(max(avg_list)))
  print(avg_list.index(min(avg_list)))
  print(min_list.index(min(avg_list)))
  print(max_list.index(max(avg_list)))
  print(var_list.index(max(avg_list)))

  # with open('./latent_v', 'wb') as f:
          #     f.write(tt)
